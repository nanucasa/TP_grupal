# TP Grupal â€“ Telco Churn  
Proyecto MLOps de PredicciÃ³n de Churn

## Proyecto ISTEA | Materia: Laboratorio de MinerÃ­a de Datos

## ğŸ‘¥ Integrantes

- **Nadia Soledad CasÃ¡**
- **Karla Silva**

-----------------------------------

## ğŸ“‹ DescripciÃ³n del Proyecto

Pipeline reproducible de Machine Learning para predecir la rotaciÃ³n de clientes (churn) en una empresa de telefonÃ­a, aplicando buenas prÃ¡cticas de MLOps con versionado de datos, tracking de experimentos y orquestaciÃ³n de assets.

**Contexto:**  
El objetivo es identificar quÃ© clientes tienen mayor probabilidad de darse de baja, utilizando informaciÃ³n de facturaciÃ³n, tipo de contrato y otros datos relacionados con el servicio. El proyecto no se queda en â€œun modelo sueltoâ€, sino que integra:

- CÃ³digo versionado en **Git/GitHub**.
- Datos y pipeline versionados con **DVC**.
- Experimentos y modelos registrados en **MLflow** (remoto en **DagsHub**).
- VisualizaciÃ³n de mÃ©tricas, grÃ¡ficos y modelo campeÃ³n con **Dagster**.

-----------------------------------

## ğŸ¯ Objetivos

- Construir un pipeline de ML completamente reproducible.
- Aplicar control de versiones con DVC y Git.
- Trackear experimentos y modelos con MLflow (DagsHub).
- Orquestar y visualizar resultados con Dagster.
- Implementar CI/CD con GitHub Actions para validar el pipeline.
- Seleccionar de forma sistemÃ¡tica un **modelo campeÃ³n** segÃºn `test_f1`.

-----------------------------------

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Python 3.10+** â€“ Lenguaje principal
- **DVC** â€“ Versionado de datos y modelos, definiciÃ³n de pipeline
- **Git/GitHub** â€“ Control de versiones de cÃ³digo
- **DagsHub** â€“ Remoto DVC + servidor MLflow
- **MLflow** â€“ Tracking de experimentos y registro de modelos
- **Dagster** â€“ OrquestaciÃ³n y visualizaciÃ³n de assets
- **scikit-learn** â€“ Modelado (Logistic Regression, etc.)
- **Pandas / NumPy** â€“ ManipulaciÃ³n de datos

-----------------------------------

## ğŸ“Š Dataset

- **Nombre:** `telco_churn.csv`
- **UbicaciÃ³n:** `data/raw/telco_churn.csv` (trackeado por DVC)
- **Target:** `churn` (1 = se da de baja, 0 = permanece)
- **Contenido:** informaciÃ³n demogrÃ¡fica, de facturaciÃ³n y del tipo de contrato del cliente.

Ejemplos de variables:

- `customer_id`: identificador Ãºnico
- `tenure` / `tenure_months`: tiempo como cliente
- `monthly_charges`: cargos mensuales
- `total_charges`: cargos acumulados
- `contract` / `contract_type`: tipo de contrato
- `churn`: variable objetivo

-----------------------------------

## âš™ï¸ Requisitos Previos

Antes de comenzar, es necesario contar con:

- Python 3.10+
- Conda / Anaconda
- Git
- DVC
- Cuenta en [DagsHub](https://dagshub.com/)
- Acceso al repositorio:

  - GitHub: `https://github.com/nanucasa/TP_grupal`
  - DagsHub: `https://dagshub.com/nanucasa/TP_grupal`

-----------------------------------

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

1. Clonar el repositorio
git clone https://github.com/nanucasa/TP_grupal.git
cd TP_grupal

. Crear entorno virtual con Conda
# Crear entorno
conda create -n tp_grupal python=3.10 -y

# Activar entorno
conda activate tp_grupal

3. Instalar dependencias
pip install -r requirements.txt

4. Configurar credenciales de DagsHub para DVC
Configurar el remoto origin de DVC con usuario y token de DagsHub:
dvc remote modify origin --local auth basic
dvc remote modify origin --local user TU_USUARIO_DAGSHUB
dvc remote modify origin --local password TU_TOKEN_DAGSHUB

5. Descargar datos versionados
dvc pull

6. Ejecutar el pipeline completo
dvc repro train_fe

Esto ejecuta las etapas necesarias hasta train_fe, actualizando datos procesados, features, modelo y mÃ©tricas.

-----------------------------------

ğŸ“ Estructura del Proyecto

TP_grupal/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # Datos originales (DVC)
â”‚   â”‚   â””â”€â”€ telco_churn.csv
â”‚   â”œâ”€â”€ processed/                # Datos limpios (DVC)
â”‚   â””â”€â”€ features/                 # Features para entrenamiento (DVC)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_prep.py              # PreparaciÃ³n de datos (limpieza + splits)
â”‚   â””â”€â”€ train.py                  # Entrenamiento + logging en MLflow
â”œâ”€â”€ models/                       # Modelos entrenados (DVC)
â”‚   â””â”€â”€ model_fe.joblib
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ import_dvc_metrics_to_mlflow.py
â”‚   â””â”€â”€ update_champion_from_runs.py   # SelecciÃ³n del modelo campeÃ³n
â”œâ”€â”€ tp_grupal_dagster/
â”‚   â””â”€â”€ tp_grupal_dagster/
â”‚       â”œâ”€â”€ assets.py             # DefiniciÃ³n de assets de Dagster
â”‚       â””â”€â”€ __init__.py           # Definitions de Dagster
â”œâ”€â”€ artifacts/
â”‚   â””â”€â”€ champion_run.json         # InformaciÃ³n del modelo campeÃ³n (generado)
â”œâ”€â”€ reports/                      # GrÃ¡ficos y reportes (curvas ROC/PR, etc.)
â”œâ”€â”€ .dvc/                         # ConfiguraciÃ³n de DVC
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/                # GitHub Actions CI/CD
â”œâ”€â”€ params.yaml                   # ParÃ¡metros configurables del pipeline
â”œâ”€â”€ dvc.yaml                      # DefiniciÃ³n del pipeline DVC (stages)
â”œâ”€â”€ dvc.lock                      # Estado del pipeline (reproducibilidad)
â”œâ”€â”€ requirements.txt              # Dependencias Python
â””â”€â”€ README.md                     # Este archivo

-----------------------------------

ğŸ”„ Pipeline de Trabajo (DVC)

El proyecto implementa un pipeline reproducible con varias etapas definidas en dvc.yaml.

Etapa 1: PreparaciÃ³n de Datos (data_prep)

- Script: src/data_prep.py

Funciones:
	- Carga del dataset crudo desde data/raw/telco_churn.csv.
	- Limpieza de datos (valores faltantes, tipos, etc.).
	- Transformaciones iniciales.
	- DivisiÃ³n en conjuntos de train / valid / test.
	- Exporta datasets limpios a data/processed/.

Entradas:
	- data/raw/telco_churn.csv
	- params.yaml

Salidas:
	- Archivos procesados en data/processed/ (train/valid/test).

Etapa 2: IngenierÃ­a de Features y Tuning (feature_eng y tune)

Functions principales:

- AplicaciÃ³n de ingenierÃ­a de caracterÃ­sticas (codificaciÃ³n, escalado, etc.).
- GeneraciÃ³n de archivos de features:
	- data/features/train_fe.csv
	- data/features/valid_fe.csv
	- y equivalentes de test
- Experimentos de tuning (distintos hiperparÃ¡metros/modelos).
- Registro de runs de tuning en MLflow.

Entradas:
- Datos de data/processed/
- params.yaml

Salidas:
	- Archivos de features en data/features/.
	- Artefactos y mÃ©tricas de tuning en MLflow.

Etapa 3: Entrenamiento Final (train_fe)
Script: src/train.py
- Funciones:
	- Carga de datos de features (train/valid y, cuando corresponde, test).
	- Entrenamiento de un modelo de Logistic Regression dentro de un pipeline StandardScaler + logisticRegression.

- CÃ¡lculo de mÃ©tricas:
	- Accuracy, Precision, Recall, F1 (valid/test)
	- ROC-AUC, PR-AUC (test)

- Logueo de parÃ¡metros, mÃ©tricas y modelo en MLflow (tracking remoto en DagsHub).
- Registro del modelo en el Model Registry de MLflow bajo el nombre TelcoChurn_LogReg.

Entradas:
	- data/features/train_fe.csv
	- data/features/valid_fe.csv
	- test features
	- params.yaml

Salidas:
	- models/model_fe.joblib
	- MÃ©tricas locales (metrics_fe.json y/o similares).
	- Runs y modelos en MLflow (experimento de entrenamiento final).

-----------------------------------

ğŸ“ˆ Reproducibilidad

Comandos Ãºtiles para trabajar con DVC:

# Ejecutar todo el pipeline (hasta train_fe)
dvc repro train_fe

# Ver el DAG del pipeline
dvc dag

# Verificar estado del pipeline
dvc status

# Ver diferencias en parÃ¡metros
dvc params diff

ğŸ”§ ConfiguraciÃ³n de ParÃ¡metros
Los parÃ¡metros configurables del pipeline estÃ¡n en params.yaml.
AhÃ­ se definen, por ejemplo:

ParÃ¡metros de divisiÃ³n de datos:
	- test_size
	- valid_size
	- random_state

Columna objetivo:
- target_column: churn

ParÃ¡metros del modelo (Logistic Regression):
	- C
	- max_iter
	- class_weight
	- etc.

Flujo tÃ­pico:
	1- Editar params.yaml.
	2- Ejecutar: dvc repro train_fe
	3- DVC re-ejecuta solo las etapas afectadas por el cambio.
	4- Las mÃ©tricas se actualizan y los nuevos runs se registran en MLflow.

-----------------------------------

ğŸ§ª Experimentos Realizados

Se ejecutaron mÃºltiples experimentos (mÃ¡s de 200 runs) variando:

- IngenierÃ­a de features (baseline vs feature engineering).
- HiperparÃ¡metros del modelo (C, max_iter, semillas).
- Distintos enfoques de entrenamiento y evaluaciÃ³n.

Los experimentos estÃ¡n organizados principalmente en los experimentos de MLflow:

	- telco_churn_baseline
	- telco_churn_baseline_fe
	- telco_churn_baseline_rf
	- telco_churn_tune_xgb

En el experimento telco_churn_tune_xgb se concentraron los runs de evaluaciÃ³n final (metrics_test*), que se usan para elegir el modelo campeÃ³n por test_f1.

-----------------------------------

ğŸ† Modelo Seleccionado (Champion)

Experimento principal: telco_churn_tune_xgb
Run campeÃ³n: metrics_test_fe
Modelo: Logistic Regression sobre features ingenieradas (TelcoChurn_LogReg)

MÃ©tricas (aprox. conjunto de test):

| MÃ©trica  | Valor aproximado   |
| -------- | ------------------ |
| F1-Score | â‰ˆ 0.60 (`test_f1`) |
| ROC-AUC  | â‰ˆ 0.74             |
| PR-AUC   | â‰ˆ 0.60             |

La selecciÃ³n del champion se realiza con:

- scripts/update_champion_from_runs.py

Este script:

	1- Se conecta al experimento telco_churn_tune_xgb en MLflow.
	2- Filtra los runs cuyo nombre comienza con metrics_test.
	3- Ordena por metrics.test_f1 de mayor a menor.
	4- Elige el mejor run como modelo campeÃ³n.
	5- Guarda la informaciÃ³n en: artifacts/champion_run.json

Ese JSON contiene:

	- experiment_name
	- experiment_id
	- primary_metric (test_f1)
	- run_id
	- run_name (ej: metrics_test_fe)
	- metric_value (valor de test_f1 del champion)

-----------------------------------

ğŸ“Š Dagster: MÃ©tricas, GrÃ¡ficos y Champion

El proyecto de Dagster vive en: tp_grupal_dagster/tp_grupal_dagster/

1- **Los assets principales son: test_metrics**

- Se conecta a MLflow remoto.
- Para cada experimento (baseline, baseline_fe, baseline_rf), obtiene el mejor run de test por f1_test.
- Devuelve un DataFrame con mÃ©tricas de test y genera reports/dagster_mlflow_test_metrics.csv.

2- **f1_barchart**

- Usa test_metrics para graficar un barplot de f1_test por modelo.
- Guarda la imagen en reports/f1_bench_dagster.png.

3- **pr_curve_fe**

- Registra la curva Precisionâ€“Recall del modelo con features.
- Lee reports/pr_curve_fe.png.
- Asocia la mÃ©trica PR-AUC (desde MLflow o valor fijo configurado).

4- **roc_curve_fe**

- Registra la curva ROC del modelo con features.
- Lee reports/roc_curve_fe.png.
- Asocia la mÃ©trica ROC-AUC (desde MLflow o valor fijo configurado).

5- **champion_run**

- Lee artifacts/champion_run.json.
- Expone en Dagster quiÃ©n es el modelo campeÃ³n y su test_f1.

-----------------------------------

ğŸ™ **CÃ³mo levantar Dagster**

	cd tp_grupal_dagster
	conda activate tp_grupal
	dagster dev

Luego abrir:
	http://127.0.0.1:3000

En la pestaÃ±a Assets se pueden materializar y visualizar:

- test_metrics
- f1_barchart
- pr_curve_fe
- roc_curve_fe
- champion_run

-----------------------------------

ğŸ”— Enlaces del Proyecto

**Repositorio GitHub:**
	https://github.com/nanucasa/TP_grupal

**Proyecto DagsHub (DVC + MLflow):**
	https://dagshub.com/nanucasa/TP_grupal

**UI MLflow (experimentos y modelos):**
	https://dagshub.com/nanucasa/TP_grupal.mlflow

-----------------------------------

ğŸš¦ CI/CD con GitHub Actions

El proyecto incluye automatizaciÃ³n con GitHub Actions en .github/workflows/, que:

- Instala dependencias (requirements.txt).
- Ejecuta dvc pull para traer datos y modelos desde el remoto.
- Ejecuta dvc repro para validar el pipeline.
- Utiliza secrets configurados en GitHub para conectarse a DagsHub.

Esto asegura que el pipeline sea reproducible en un entorno limpio ante cada push o pull request.

-----------------------------------

ğŸ› ResoluciÃ³n de Problemas

- Error: dvc pull falla

Verificar configuraciÃ³n del remote: dvc remote list

Reconfigurar credenciales (usuario/token DagsHub):
dvc remote modify origin --local auth basic
dvc remote modify origin --local user TU_USUARIO
dvc remote modify origin --local password TU_TOKEN

- Error: dvc repro no detecta cambios

Forzar re-ejecuciÃ³n de una etapa especÃ­fica: dvc repro -f data_prep
O de todo el pipeline hasta train_fe: dvc repro -f train_fe

- Error: falta algÃºn archivo
dvc pull
dvc status

-----------------------------------

ğŸ“Œ Resultados Finales
Modelo en â€œProducciÃ³nâ€ (Champion interno)

Algoritmo seleccionado: Logistic Regression sobre features ingenieradas
Run: metrics_test_fe (experimento telco_churn_tune_xgb)
MÃ©trica principal: test_f1 â‰ˆ 0.60

El modelo logra un compromiso razonable entre:
	buena F1 en test,
	buen ROC-AUC (~0.74) y PR-AUC (~0.60),
	y una implementaciÃ³n simple y fÃ¡cilmente desplegable.

Visualizaciones

El pipeline genera:
	1- Curva ROC y curva Precisionâ€“Recall del modelo FE en reports/.
	2- GrÃ¡fico de barras de F1 por modelo (f1_bench_dagster.png) vÃ­a Dagster.
	3- DataFrame consolidado de mÃ©tricas de test (dagster_mlflow_test_metrics.csv).

-----------------------------------


ğŸš€ Deployment

La estrategia de deployment propuesta (API REST, batch, monitoreo y reentrenamiento) se documenta en:

DEPLOYMENT.md

-----------------------------------

ğŸ‘¤ Autoras

Nadia Soledad CasÃ¡
Karla Silva

Curso: Laboratorio de MinerÃ­a de Datos â€“ ISTEA
AÃ±o: 2025
