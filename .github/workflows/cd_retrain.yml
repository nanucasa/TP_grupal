name: CD - Retrain model and push to Dagshub

on:
  # Se dispara a mano desde la pestaña "Actions" (Run workflow)
  workflow_dispatch:

jobs:
  retrain:
    runs-on: ubuntu-latest

    env:
      # MLflow remoto en Dagshub
      MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
      MLFLOW_TRACKING_USERNAME: ${{ secrets.DAGSHUB_USERNAME }}
      MLFLOW_TRACKING_PASSWORD: ${{ secrets.DAGSHUB_TOKEN }}

      # DVC remoto en Dagshub
      DAGSHUB_USERNAME: ${{ secrets.DAGSHUB_USERNAME }}
      DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Configure DVC remote for Dagshub
        run: |
          dvc remote modify dagshub url https://$DAGSHUB_USERNAME:$DAGSHUB_TOKEN@dagshub.com/nanucasa/TP_grupal.dvc
          dvc remote default dagshub
        continue-on-error: true

      - name: Pull data and artifacts from DVC
        run: |
          dvc pull
        continue-on-error: true

      # Sanity check: verifica que podemos loguear en MLflow remoto
      - name: Sanity check MLflow logging
        run: |
          python - << "EOF"
          import mlflow
          print("Tracking URI en job:", mlflow.get_tracking_uri())
          mlflow.set_experiment("ci_cd_sanity")
          with mlflow.start_run(run_name="gh_actions_smoke"):
              mlflow.log_metric("test_metric", 1.23)
          EOF

      # Aquí se generan los runs "reales" (local + Dagshub)
      - name: Retrain model and log to MLflow (Dagshub)
        run: |
          python scripts/base_scripts_runs.py

      - name: Push updated data/models to DVC remote
        run: |
          dvc push
        continue-on-error: true
