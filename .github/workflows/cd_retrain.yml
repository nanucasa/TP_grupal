name: CD - Retrain model and push to Dagshub

on:
  # Lo podés disparar a mano desde la pestaña "Actions"
  workflow_dispatch:

  # Opcional: también cuando cambian cosas del modelo/pipeline en main
  push:
    branches: [ main ]
    paths:
      - "src/**"
      - "scripts/**"
      - "params.yaml"
      - "dvc.yaml"

jobs:
  retrain:
    runs-on: ubuntu-latest

    env:
      # MLflow remoto en Dagshub
      MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
      MLFLOW_TRACKING_USERNAME: ${{ secrets.DAGSHUB_USERNAME }}
      MLFLOW_TRACKING_PASSWORD: ${{ secrets.DAGSHUB_TOKEN }}

      # Para DVC remoto en Dagshub
      DAGSHUB_USERNAME: ${{ secrets.DAGSHUB_USERNAME }}
      DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Configure DVC remote for Dagshub
        run: |
          dvc remote modify dagshub url https://$DAGSHUB_USERNAME:$DAGSHUB_TOKEN@dagshub.com/nanucasa/TP_grupal.dvc
          dvc remote default dagshub
        continue-on-error: true

      - name: Pull data and artifacts from DVC
        run: |
          dvc pull

      # Sanity-check: loguear 1 run mínimo para validar MLflow remoto
      - name: Sanity check MLflow logging
        run: |
          python - << "EOF"
          import mlflow, os
          print("Tracking URI:", mlflow.get_tracking_uri())
          mlflow.set_experiment("ci_cd_sanity")
          with mlflow.start_run(run_name="gh_actions_smoke"):
              mlflow.log_metric("test_metric", 1.23)
          EOF

      - name: Retrain model and log to MLflow (Dagshub)
        run: |
          python scripts/base_scripts_runs.py

      - name: Push updated data/models to DVC remote
        run: |
          dvc push
        continue-on-error: true
