# Parámetros globales de entrenamiento y tuning
train:
  C: 1.0
  max_iter: 1000
  seed: 42

tune:
  cv: 1            # según tu script 'tune.py' (antes faltaba y daba KeyError)
  scoring: f1
  n_jobs: -1

# RandomForest: espacio de búsqueda para tune_rf.py
rf:
  param_grid:
    n_estimators: [200, 300, 400]
    max_depth: [None, 5, 8]
    min_samples_split: [2, 5, 10]
  random_state: 42

# XGBoost: espacio de búsqueda y defaults para tune_xgb.py
xgb:
  param_grid:
    n_estimators: [200, 300, 500]
    max_depth: [3, 4, 5]
    learning_rate: [0.05, 0.1, 0.2]
    subsample: [0.8, 1.0]
    colsample_bytree: [0.8, 1.0]
    reg_lambda: [1.0, 2.0]
  tree_method: hist
  n_jobs: -1
  eval_metric: logloss
  random_state: 42

# Búsqueda de umbral para threshold.py
threshold:
  metric: f1
  grid_size: 101   # 0.00..1.00 con paso 0.01

# Etiquetas del reporte comparativo (src/report_benchmark.py)
report:
  labels:
    logreg: "Logistic Regression"
    rf: "RandomForest"
    xgb: "XGBoost"
    fe: "LR + FE"
