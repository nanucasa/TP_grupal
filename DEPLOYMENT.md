# Estrategia de Deployment - TP Grupal Telco Churn

üìù ## Resumen del Modelo

- **Algoritmo:** Logistic Regression (pipeline `StandardScaler + LogisticRegression` sobre features ingenieradas)
- **Dataset:** `telco_churn.csv` (~10.000 clientes de telecomunicaciones)
- **M√©trica principal:** F1-Score en test (`test_f1`)
- **M√©tricas aproximadas (conjunto de test):**
  - Accuracy ‚âà 66 %
  - F1-Score ‚âà 60 %
  - ROC-AUC ‚âà 74 %
  - PR-AUC ‚âà 60 %

El modelo campe√≥n se selecciona autom√°ticamente a partir de los runs registrados en MLflow (tracking remoto en DagsHub), usando el script `scripts/update_champion_from_runs.py`, que:

- Toma el experimento `telco_churn_tune_xgb`.
- Filtra los runs cuyo nombre comienza con `metrics_test`.
- Ordena por `metrics.test_f1`.
- Elige el mejor como **champion** y guarda la informaci√≥n en `artifacts/champion_run.json`.

-----------------------------------

## Propuesta de Arquitectura

### Opci√≥n 1: API REST con FastAPI

Servicio REST que expone un endpoint de scoring para predecir churn en l√≠nea para uno o varios clientes.

```python
from fastapi import FastAPI
import joblib
import pandas as pd
import json
from pathlib import Path

app = FastAPI()

# Cargar informaci√≥n del champion (run_id, m√©trica, etc.)
champion_path = Path("artifacts/champion_run.json")
with open(champion_path, "r", encoding="utf-8") as f:
    champion = json.load(f)

# Versi√≥n simple: cargar el modelo final entrenado
# En este TP el modelo final se guarda como models/model_fe.joblib
model = joblib.load("models/model_fe.joblib")


@app.post("/predict")
def predict(customer_data: dict):
    df = pd.DataFrame([customer_data])

    # Probabilidad de churn (clase positiva)
    proba = model.predict_proba(df)[0, 1]
    pred = int(proba >= 0.5)

    return {
        "churn": pred,
        "probability": float(proba),
        "champion_run_id": champion["run_id"],
        "champion_experiment": champion["experiment_name"],
    }
```
---------------------------------

Stack sugerido:
	- FastAPI + Uvicorn
	- Docker container
	- Deploy en Azure Container Apps o GCP Cloud Run
	- MLflow (en DagsHub) como registry de modelos y runs

El servicio puede actualizarse leyendo peri√≥dicamente artifacts/champion_run.json o exponiendo un endpoint interno para recargar el modelo cuando cambie el champion.

---------------------------------

Opci√≥n 2: Batch Processing

1- Pipeline batch programado (por ejemplo con Dagster) que:
2- Lee peri√≥dicamente nuevos clientes desde una base de datos (clientes activos).
3- Genera predicciones de churn usando el modelo campe√≥n.
4- Guarda resultados en una tabla de scoring (ej. churn_scores) con:
	- customer_id
	- score_churn
	- flag_alto_riesgo
	- fecha_scoring
4- Dispara reportes o dashboards para el √°rea de negocio (lista de clientes de alto riesgo para acciones de retenci√≥n).

Stack sugerido:
- Dagster para orquestaci√≥n de jobs batch.
- Base de datos: PostgreSQL o BigQuery (seg√∫n infraestructura).
- Jobs containerizados (Docker) ejecutados en:
	- VM con cron + Dagster, o
	- Cluster ligero (Docker Swarm / Kubernetes) si la escala lo justifica.
- MLflow (DagsHub) como fuente de verdad del champion y de las m√©tricas hist√≥ricas.

---------------------------------

üîé Monitoreo

M√©tricas a trackear
1- Performance del modelo
	- Accuracy, F1, ROC-AUC, PR-AUC en ventanas de tiempo recientes.
	- Comparaci√≥n vs. m√©tricas del conjunto de test original.

Data Drift
- Distribuci√≥n de features cr√≠ticas (ej. tenure_months, monthly_charges, contract_type) vs. entrenamiento.
- Detecci√≥n de cambios en la proporci√≥n de clases (churn vs no churn).

Prediction Drift
- Distribuci√≥n de probabilidades de churn a lo largo del tiempo.
- Porcentaje de clientes marcados como alto riesgo.

Herramientas
- MLflow + DagsHub para:
	Registrar nuevos runs.
	Comparar m√©tricas entre versiones de modelo.
	Llevar historial de champions.

- Evidently AI (u otra librer√≠a similar) para:
	Reportes de data drift y prediction drift.
	Comparaci√≥n entre dataset de entrenamiento y datos recientes.
- Grafana / Loki o servicios equivalentes para:
	Monitorear tiempos de respuesta, tasa de errores, throughput.
	Visualizar logs estructurados del endpoint /predict o de los jobs batch.

---------------------------------

‚ôªÔ∏è Actualizaci√≥n del Modelo

Triggers de reentrenamiento

- Degradaci√≥n de performance:
	- test_f1 de datos recientes cae por debajo de un umbral (ej. 0.55).
- Data drift significativo en uno o m√°s features clave.
- Pol√≠tica de calendario:
	- Reentrenar cada N meses (ej. trimestralmente) aunque no haya alarmas.

Proceso propuesto:

1- Reentrenamiento con DVC
- Actualizar datos (nuevos per√≠odos / nuevos clientes) en el remoto de DVC.
- Ejecutar:
	- dvc pull
	- dvc repro train_fe
- Esto vuelve a correr el pipeline de preparaci√≥n, features y entrenamiento.

2- Registro de experimentos
- Los nuevos runs se registran en MLflow (en DagsHub), incluyendo:
	- par√°metros,
	- m√©tricas de train/valid/test,
	- artefactos (modelo, gr√°ficos, etc.).
3- Selecci√≥n autom√°tica de champion
	- Ejecutar: python scripts/update_champion_from_runs.py
El script:

- toma el experimento telco_churn_tune_xgb,
- filtra metrics_test*,
- elige el mejor test_f1,
- actualiza artifacts/champion_run.json.

4- Actualizaci√≥n de servicios

- API REST:  El servicio recarga el modelo (por lectura de champion_run.json o por reinicio controlado del contenedor).

- Batch (Dagster): Los jobs de scoring usan el modelo asociado al nuevo champion en los siguientes ciclos.

5- Validaci√≥n
- Antes de exponer el nuevo modelo a 100 % del tr√°fico:
	- Revisar m√©tricas en MLflow.
	- Comparar champion nuevo vs anterior.
Opcional: A/B testing sobre una fracci√≥n de clientes o tr√°fico.

---------------------------------

üîê Consideraciones de Seguridad

Autenticaci√≥n y autorizaci√≥n
	API protegida con tokens (API Keys) o JWT.
	Control de acceso a endpoints internos (ej. recarga de modelo).

Rate limiting
	Limitar cantidad de requests por unidad de tiempo para cada cliente/aplicaci√≥n.

Validaci√≥n de entrada
	Validar tipos, rangos y categor√≠as de cada campo (ej. contract_type, payment_method).
	Descartar o registrar inputs malformados.

Cifrado
	Todo el tr√°fico hacia la API debe ir sobre HTTPS (TLS).

Logs de auditor√≠a
	Registrar:
		qui√©n llam√≥ al servicio (ID de cliente o sistema),
		qu√© payload envi√≥ (resumen),
		qu√© score se devolvi√≥,
		timestamp.
	Guardar logs de errores y excepciones.

Protecci√≥n de secretos
	Tokens de DagsHub, credenciales de BD y claves de acceso en: 
		variables de entorno,
		secretos en el orquestador (Dagster),
		secret manager del cloud.
	Nunca en el c√≥digo fuente o en el repositorio.

---------------------------------

ü´∞Estimaci√≥n de Costos

Ejemplo de estimaci√≥n para una arquitectura ligera:

API REST (FastAPI + Docker) en servicio gestionado (Azure Container Apps / GCP Cloud Run)
	Tr√°fico moderado (hasta cientos de miles de requests/mes):
		Costos de c√≥mputo en el orden de pocos d√≥lares mensuales.

Almacenamiento
	Modelos y artefactos en almacenamiento de objetos (Blob Storage / GCS / S3 v√≠a DagsHub):
		Muy bajo costo (centavos de d√≥lar por GB/mes).

Monitoreo
	Stack de observabilidad b√°sico:
		Puede ser auto-hosted (bajo costo infra) o servicio administrado (costo variable).

Los valores exactos dependen del proveedor cloud, regi√≥n y volumen de tr√°fico y datos.

---------------------------------

üë£ Pr√≥ximos Pasos

1- Definir el modo principal de uso del modelo:
	online (API REST),
	batch (scoring peri√≥dico),
	o combinaci√≥n de ambos.
2- Crear un Dockerfile que incluya:
	c√≥digo del proyecto,
	entorno (requirements.txt),
	l√≥gica para cargar el champion desde MLflow / champion_run.json.
3- Integrar el build y deploy en GitHub Actions:
	job de test + dvc repro para validar el pipeline,
	build de imagen,
	deploy automatizado a un entorno de staging.
4- Configurar monitoreo:
	reportes de drift (Evidently / similar),
	dashboards de m√©tricas t√©cnicas (latencia, errores),
	alertas por ca√≠da de test_f1 o aumento de errores.
5- Documentar un runbook operacional:
	qu√© hacer si la API deja de responder,
	qu√© hacer si las m√©tricas bajan,
	c√≥mo ejecutar reentrenamientos,
	c√≥mo forzar un rollback al champion anterior en caso de problemas.

